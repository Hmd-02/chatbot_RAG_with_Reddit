# ğŸ¤– Chatbot Reddit sur l'IA et la Data Science

Ce projet a pour objectif de construire un **chatbot intelligent** Ã  partir de conversations Reddit issues de subreddits spÃ©cialisÃ©s en **Intelligence Artificielle** et **Data Science**. Le modÃ¨le est fine-tunÃ© sur **GPT-2 Medium** Ã  partir de dialogues rÃ©els pour offrir des rÃ©ponses cohÃ©rentes et naturelles.

---

## ğŸ“ Structure du projet

```
â”œâ”€â”€ extraction_des_donnees.ipynb
â”œâ”€â”€ analyse.ipynb
â”œâ”€â”€ preprocessing.ipynb
â”œâ”€â”€ chatbot.ipynb
â”œâ”€â”€ README.md
â”œâ”€â”€ data/  â†’ donnÃ©es Reddit (disponibles via lien externe)
â””â”€â”€ modele/ â†’ modÃ¨le fine-tunÃ© (disponible via Drive)
```

---

## ğŸ“Œ Description des notebooks

### ğŸ”¸ `extraction_des_donnees.ipynb`
- Extraction automatique des posts et commentaires Ã  l'aide de **PRAW** (Python Reddit API Wrapper).
- Ciblage de **5 subreddits** centrÃ©s sur l'IA et la Data Science : `r/MachineLearning`, `r/datascience`, `r/deeplearning`, `r/artificial`, `r/ArtificialInteligence`.
- Sauvegarde des donnÃ©es sous format brut .

---

### ğŸ“Š `analyse.ipynb`
- Analyse exploratoire des posts et commentaires extraits.
- Visualisation des **nuages de mots** sur les thÃ©matiques rÃ©currentes.
- **Analyse de sentiment** des messages pour mieux comprendre les tonalitÃ©s.
- Statistiques descriptives sur la longueur, la frÃ©quence des mots, la distribution des commentaires, etc.

---

### ğŸ§¹ `preprocessing.ipynb`
- Nettoyage des textes : suppression des caractÃ¨res spÃ©ciaux, normalisation, etc.
- Filtrage des messages trop courts ou non informatifs.
- Mise au format `.txt` pour l'entraÃ®nement GPT-2.

---

### ğŸ§  `chatbot.ipynb`
- **Tokenisation et vectorisation** des donnÃ©es textuelles.
- TÃ©lÃ©chargement du modÃ¨le **GPT-2 Medium** via Hugging Face.
- Fine-tuning sur les dialogues Reddit.
- Construction d'une **interface conversationnelle avec Gradio** pour interagir avec le chatbot.

---

## ğŸ—ƒ Dossiers lourds (donnÃ©es & modÃ¨le)

### ğŸ“¦ DonnÃ©es Reddit
Le dossier `data/` contient l'ensemble des messages extraits (~230 Mo).  
ğŸ“… AccÃ¨s direct : [Lien Drive vers les donnÃ©es](https://drive.google.com/drive/folders/1GED4nMp0PecYyOnp9UcnlPWvsBt25Lwb?usp=sharing)

### ğŸ§  ModÃ¨le Fine-tunÃ©
Le dossier `modele/` contient le modÃ¨le GPT-2 fine-tunÃ© (~1.3 Go).  
ğŸ“… AccÃ¨s direct : [Lien Drive vers le modÃ¨le](https://drive.google.com/drive/folders/1GED4nMp0PecYyOnp9UcnlPWvsBt25Lwb?usp=sharing)

---

## ğŸ§ª ExÃ©cution (sur kaggle conseillÃ© car disponibilitÃ© de gpu gratuit pour 30H par semaine)

Pour exÃ©cuter le projet (en local) :

1. Cloner ce dÃ©pÃ´t :
```bash
git clone https://github.com/Hmd-02/chatbot_RAG_with_Reddit.git
cd chatbot_RAG_with_Reddit
```

2. TÃ©lÃ©charger les fichiers `data/` et `modele/` et les placer dans le mÃªme repertoire que le script `chatbot` et s'assurer de modifier les chemin d'accÃ¨s avant d'exÃ©cuter


3. Installer les dÃ©pendances :
```bash
pip install -r requirements.txt
```

4. Lancer l'interface Gradio :
```bash
python chatbot.ipynb  # ou via Jupyter
```

---

## ğŸ’¡ Objectifs

Ce projet sâ€™inscrit dans une logique dâ€™apprentissage (projet du cours de NLP) autour de :
- Lâ€™**extraction de donnÃ©es web (API Reddit)**.
- Le **prÃ©traitement NLP** avancÃ©.
- Le fine-tuning dâ€™un modÃ¨le **transformer prÃ©entraÃ®nÃ© (GPT-2)**.
- Lâ€™analyse de **donnÃ©es conversationnelles** rÃ©elles.
- La mise en place dâ€™une interface interactive de **chatbot**.

---

## ğŸ“š Technologies utilisÃ©es

- Python, Jupyter Notebooks
- PRAW, pandas, matplotlib, seaborn
- NLTK, transformers (HuggingFace), Gradio
- Google Drive pour la gestion des fichiers lourds

---

## ğŸ“¢ Contact

Pour toute question, suggestion ou contribution :  
**Auteur :** [FaÃ¯Ã§al OUEDRAOGO - Fatimata TALL - Ange DASSI / Hmd-02]  
ğŸ“§ Email : aide.app.ofch@gmail.com

